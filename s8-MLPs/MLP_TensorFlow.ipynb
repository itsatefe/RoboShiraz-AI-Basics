{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cf8352",
   "metadata": {},
   "source": [
    "# MLP with **TensorFlow/Keras** — Binary Classification\n",
    "\n",
    "In this notebook you'll train a small **Multi-Layer Perceptron (MLP)** using **TensorFlow/Keras** on a simple 2‑D synthetic dataset.\n",
    "\n",
    "What you'll learn:\n",
    "- Building a dataset (two Gaussian blobs) for binary classification  \n",
    "- Defining an MLP with `tf.keras.Sequential`  \n",
    "- Compiling with loss/optimizer/metrics and training with `.fit()`  \n",
    "- Plotting **loss** and **accuracy** curves  \n",
    "- Visualizing the **decision boundary**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51726b",
   "metadata": {},
   "source": [
    "> **Note:** If `tensorflow` isn't installed in your environment, please install it first.  \n",
    "> In many environments: `pip install tensorflow`  \n",
    "> (Skip this if TensorFlow is already available.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b257d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# TensorFlow / Keras\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Reproducibility (best-effort)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac248002",
   "metadata": {},
   "source": [
    "## 1) Create a Simple 2-D Dataset (Binary Classification)\n",
    "\n",
    "Two clusters (class 0 and class 1). We'll split into train/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_blobs(n_per_class=200, spread=1.2):\n",
    "    mean0 = np.array([-2.0, -2.0])\n",
    "    mean1 = np.array([ 2.0,  2.0])\n",
    "    cov = np.array([[spread, 0.0],[0.0, spread]])\n",
    "    X0 = np.random.multivariate_normal(mean0, cov, n_per_class)\n",
    "    X1 = np.random.multivariate_normal(mean1, cov, n_per_class)\n",
    "    X = np.vstack([X0, X1]).astype(\"float32\")\n",
    "    y = np.hstack([np.zeros(n_per_class), np.ones(n_per_class)]).astype(\"float32\")\n",
    "    return X, y\n",
    "\n",
    "X, y = make_blobs(n_per_class=300, spread=1.5)\n",
    "\n",
    "# Train/test split\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "train_ratio = 0.75\n",
    "split = int(train_ratio * len(X))\n",
    "train_idx, test_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test,  y_test  = X[test_idx],  y[test_idx]\n",
    "\n",
    "# Quick visualization\n",
    "plt.figure()\n",
    "plt.scatter(X_train[:,0], X_train[:,1], s=10)\n",
    "plt.title(\"Training Samples (2D points)\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ec672",
   "metadata": {},
   "source": [
    "## 2) Define the MLP Model (Keras `Sequential`)\n",
    "\n",
    "We'll use a small network:\n",
    "\n",
    "- Dense(16, ReLU) → Dense(8, ReLU) → Dense(1, Sigmoid)\n",
    "\n",
    "The sigmoid output gives a probability of class **1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(2,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d268a",
   "metadata": {},
   "source": [
    "## 3) Compile & Train\n",
    "\n",
    "- **Loss:** `binary_crossentropy`  \n",
    "- **Optimizer:** `adam`  \n",
    "- **Metrics:** `accuracy`  \n",
    "- We'll also track validation performance with `validation_split=0.2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0  # set 1 to see per-epoch logs\n",
    ")\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title(\"Binary Cross-Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014abbbd",
   "metadata": {},
   "source": [
    "## 4) Evaluate on the Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", round(float(test_loss), 4))\n",
    "print(\"Test acc :\", round(float(test_acc), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdebf922",
   "metadata": {},
   "source": [
    "## 5) Visualize the Decision Boundary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary_keras(model, X, y, steps=200, padding=1.0):\n",
    "    x_min, x_max = X[:,0].min()-padding, X[:,0].max()+padding\n",
    "    y_min, y_max = X[:,1].min()-padding, X[:,1].max()+padding\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, steps),\n",
    "        np.linspace(y_min, y_max, steps)\n",
    "    )\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()].astype(\"float32\")\n",
    "    probs = model.predict(grid, verbose=0).reshape(xx.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, probs, levels=20, alpha=0.5)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, s=10)\n",
    "    plt.title(\"Decision Boundary — TensorFlow MLP\")\n",
    "    plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary_keras(model, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88613596",
   "metadata": {},
   "source": [
    "## 6) Tips & Exercises\n",
    "\n",
    "- Try different widths/depths: e.g., 1 hidden layer with 4 units vs. 2 layers with 32 units.  \n",
    "- Tune learning rate: `learning_rate=0.001` vs `0.01`.  \n",
    "- Add regularization: `layers.Dense(16, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4))`.  \n",
    "- Switch activation to `tanh` and compare learning curves.  \n",
    "- Increase overlap between the two blobs to make classification harder.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scrapingenv]",
   "language": "python",
   "name": "conda-env-scrapingenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
